[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to PAMGuard Help",
    "section": "",
    "text": "This is a web version of the PAMGuard online help.\nPlease note that not all of the functionality of the online help system translates perfectly to a web browser, so there may be functionality in the online help that is not replicated here.\nUse the sidebar navigation to find your way through the help pages.\nIf you cannot see the side bar, expand the width of your browser window and it will appear."
  },
  {
    "objectID": "docs/batchoverview.html",
    "href": "docs/batchoverview.html",
    "title": "Overview",
    "section": "",
    "text": "The Batch Processing module can be used to run the same configuration file on multiple datasets without having to go into the configuration for every dataset to change the location of the source files, the output database name, and the location of the binary store.\nIt is particularly useful for processing datasets from deployments of multiple autonomous recorders, but also has application in re-processing of any data where you want to run the same PAMGuard algorithms on multiple sets of data. For instance if a new detector becomes available, you may want to re-process multiple sets of data from old cruises.\nThe module can process raw data using PAMGuard Normal Mode to run detectors on folders of sound files (Figure 1).\nIt can also be used to process data in PAMGuard Viewer Mode to perform tasks such as reclassifying clicks, or running the click train detector.\n\nFigure 1. Normal mode processing of raw audio data\n\nInstallation\nThe batch processing module is a plugin module, which needs to be added to your PAMGuard installation\nIf you’re reading this in the PAMGUard online help, you’ve already installed the Batch Processing module.\nOtherwise, you need to download the latest jar file using the links from the PAMGuard plugins pages, then copy the jar file into your plugins folder (e.g. C:\\Program Files\\Pamguard\\plugins) from where PAMGuard will automatically add it to the list of available modules in the Utilities menu next time you run PAMGuard.\nNext: Configuring the batch processor.",
    "crumbs": [
      "PAMGuard Website",
      "Batch Processing ",
      "Overview"
    ]
  },
  {
    "objectID": "docs/batchdiy.html",
    "href": "docs/batchdiy.html",
    "title": "DIY Batch Control",
    "section": "",
    "text": "While the batch processor module is useful if you’re working on a desktop computer, the functions built into PAMGuard to support batch processing can be controlled from other languages and it should be able to set up PAMGuard jobs to run on a server.\nEffectively, all that the batch processor is doing, is launching PAMGuard with a lot of extra command line options. For instance, the command line of a typical job (from the batch processing tutorial) might be something like:\n“-batch” “-psf” “C:\\ProjectData\\Compass\\compass_settings_static_logger_Job1.psfx” “-wavfilefolder” “C:\\ProjectData\\Compass\\soundtrapdata\\Hyskeir” “-binaryfolder” “C:\\ProjectData\\Compass\\PAMGuardOutput\\Hyskeir_binary” “-databasefile” “C:\\ProjectData\\Compass\\PAMGuardOutput\\Hyskeir_database” “-autostart” “-reprocessoption” “CONTINUECURRENTFILE” “-multicast” “230.1.1.1” “12346” “-netSend.id1” “1” “-netSend.id2” “5054”\nThe meanings of these commands are documented on GitHub\nAs an example, the Matlab code below will search for folders of wav files and then run the same configuration on each folder of wav’s, using the folder name to generate binary folder and database names.\nroot = ‘C:\\ProjectData\\DCLDE2024\\’; psfx = ‘C:\\ProjectData\\DCLDE2024\\dclde2024rw.psfx’; pgExe = ‘C:\\Program Files\\Pamguard\\Pamguard.exe’ subdirs = dir(root); for i = 1:numel(subdirs) if (subdirs(i).isdir == false) continue end subPath = fullfile(root, subdirs(i).name); wavs = dir([subPath, ‘\\*.wav’]); if numel(wavs) == 0 continue end % now make a new binary folder name and database name based on the path binName = fullfile(root, [subdirs(i).name, ‘binary’]); dbName = fullfile(root, [subdirs(i).name, ‘database.sqlite3’]); % see https://github.com/douggillespie/PAMGuard/wiki/Command-Line commandOpts = sprintf(‘-psf “%s” -wavfilefolder “%s” -binaryfolder “%s” -databasefile “%s” -autostart -autoexit’, … psfx, subPath, binName, dbName); fullCmd = sprintf(‘“%s” %s’, pgExe, commandOpts); pgOut{i} = system(fullCmd); fprintf(‘completed PAMGuard run on %s\\n’, subdirs(i).name) end\nPrevious: Creating Batch Jobs.",
    "crumbs": [
      "PAMGuard Website",
      "Batch Processing ",
      "DIY Batch Control"
    ]
  },
  {
    "objectID": "docs/batchconfiguration.html",
    "href": "docs/batchconfiguration.html",
    "title": "Configuration (Normal mode)",
    "section": "",
    "text": "Whether you are planning to run jobs in Normal Mode to process raw data, or whether you plan to use Viewer Mode to run tasks on processed data, the Batch Processor module always runs in Normal Mode.\nTo configure the batch processor, start PAMGuard in normal mode with a new / blank configuration and add two modules: a database and the batch processor module.\nNo other modules should be added to the configuration, except perhaps a User Input module which would allow you to make notes about what you’ve been doing with the batch processor.\nOn no account should you add any Sound Processing, or Detection, Classification, or Localisation modules to this configuration which should now look something like the image below.\n\n\nSelect Operation Mode\nIn the top left “Job Control” panel select “Raw data processing (normal mode)”.\n\n\nDetector Configuration\nThe detectors and other sound processing you want to perform on your data are all controlled from the Configuration panel at the top of the display. Here, you select the configuration file that you want to use to process all of your different batch jobs with exactly the same settings.\nThe most common thing to do, is to take a configuration file that you are already happy with, and have tested on some of the data, and select that configuration using the Browse button, however, you can also use the Browse button to create an empty configuration to work with and then add the modules you require.\nTo view or modify the configuration, press “Launch Configuration”. This will open the configuration in a separate PAMGuard window where you can view and modify any of the sound processing and detector settings.\nDon’t worry about which folder of sound files, database, and binary store are set in the configuration. These will all be overwritten with new values for each job when it runs.\nRemember to save the configuration when you’ve made modification, or the changes may not get used when you come to process new data\n\n\nCalibration Data\nEven if you’ve deployed near identical instruments, you may have slightly different calibration data for each one, or perhaps hydrophone spacing changed slightly in towed arrays used in different years. Once you’ve added jobs you can set calibration data individually for each dataset. Changes to the hydrophones are the only differences you’ll be able to make between the configuration running on each of your datasets.\nPrevious: Batch Processor overview.\nNext: Creating Offline Tasks.",
    "crumbs": [
      "PAMGuard Website",
      "Batch Processing ",
      "Configuration (Normal mode)"
    ]
  },
  {
    "objectID": "docs/batchconfiguration_v.html",
    "href": "docs/batchconfiguration_v.html",
    "title": "Configure Offline Tasks",
    "section": "",
    "text": "Whether you are planning to run jobs in Normal Mode to process raw data, or whether you plan to use Viewer Mode to run tasks on processed data, the Batch Processor module always runs in Normal Mode.\nTo configure the batch processor, start PAMGuard in normal mode with a new / blank configuration and add two modules: a database and the batch processor module.\nNo other modules should be added to the configuration, except perhaps a User Input module which would allow you to make notes about what you’ve been doing with the batch processor.\nOn no account should you add any Sound Processing, or Detection, Classification, or Localisation modules.\n\nSelect Operation Mode\nIn the top left “Job Control” panel select “Offline tasks (viewer mode)” from the drop-down menu. When you change this selection you’ll notice that the display panels below change slightly reflecting the different available options for the offlie tasks operation mode.\nOnce you’ve selected a psfx file that contains offline tasks and setup some jobs, the display should now look something like the image below.\n\n\n\nViewer Task Configuration\nConfiguring offline tasks, such as re-running click classification, for Viewer mode is a bit more complicated than for the normal mode data processing. This is because each Viewer database already contains a copy of the configuration and the multiple databases and accompanying binary data may all have different configurations.\nTo address this, as with the normal mode processing, you’ll use a psfx file to hold a master configuration for the tasks you want to run. As each task runs, the batch processor will check the configuration in the dataset about to be processed and will do its best to ensure that the configuration for the dataset is compatible with the task to run.\nThe most common thing to do, is to work with one of your datasets in Viewer mode to get tasks set up in the way that you want them, then extract the configuration from that viewer database into a psfx file to use with the batch processor. See below to see how to make additional changes to tasks from within the batch processor display.\nDon’t worry about which folder of sound files, database, and binary store are set in the configuration. These will all be overwritten with new values for each job when it runs.\nBefore it starts a job, PAMGuard will:\n\nIf the PAMGuard module required for the task is not present, the module will be added to each datasets configuration.\nThe configuration settings for that module will all be copied over from the psfx configuration irrespective of whether the module was already present, or if it was just added.\nThe configuration of other modules in each dataset will not be altered.\n\nIf the configurations differ considerably, there is no guarantee that the offline tasks will run correctly. For example if you were starting with two similar configurations, both of which had a click detector, but one was called “Click Detector” and the other configuration had called it “HF Click Detector” you’ll not be able to use the same batch job configuration.\n\nExtracting an existing Viewer configuration into a psfx file\nIt’s possible that you have some PAMGuard datasets, each consisting of a database and a folder of binary data, but no longer have the psfx file used to generate those datasets. There are three ways in which you can quite easily recreate the psfx file to use with the batch processor:\n\nLook in the folders of binary data. Each time PAMGuard starts it copies the psfx configuration into the first binary folder it generates. So the binary folders should contain an exact copy of the configuration used to generate that dataset.\nOpen one of your datasets in Viewer Mode, then from the file menu select the option Export Configuration … and save the configuration somewhere on your system.\nGenerate your list of jobs you’re going to run the tasks on, right click on any of the jobs in the “Job Detail table” and select the menu item Extract Configuration from database … which will allow you to save the configuration in psfx format.\n\n\n\nAdding new modules\nOffline tasks can have entirely new modules added and will process their offline tasks so long as the module would not normally work on raw input data. For instance, if you added a new Click Detector at this stage, nothing will happen because the click detector expects to process raw data. Your could however add a Click Train Detector to an existing configuration and it will search existing click detector output for click trains. Next time you open the datasets you processed with the additional detector you’ll find it’s added to the configuration and that the database has tables of detected click trains.\n\n\nTasks list\nA list of available tasks will automatically be extracted from the master psfx file and displayed in the Offline tasks table in the lower half of the display. The list will reflect tasks available in the configuration you’re working with. In this example the configuration has two click detectors, each of which has four standard tasks (click classification, echo detection, delay calculation, and bearing calculation). A Click Train Detector module, which has two offline tasks for detection and classification, is connected to the output of the Minke Pulse Detector and an Alarm module to the output of the SoundTrap Click Detector. The task panel therefore contains a total of 11 different tasks.\n\nFor each task, the table shows the PAMGuard module running the tasks, the name of the task, the input to the task and which data are modified by the task. There is also a column where you select which tasks you want to run (it probably won’t be all of them) and a button for editing settings if they are available.\n\n\nChanging task settings\nThere are two ways of changing the task settings.\n\nOpen the psfx file from the Configuration panel and change the settings there. Again remember to save the configuration or the changes will not get used.\nOn the Offline tasks table, click on the button to the right of each task “Configure Task” and the settings for that task should show in a popup dialog. Once the dialog is closed, the settings will be applied to all jobs (apart from any already running).\n\n\n\n\nProject Information (Project Metadata)\nIt is assumed that all jobs in a set will want to share the same project information (metadata). This is particularly important if you’re exporting data to a Tethys database.\nAs each job starts, the project information will be copied from the batch configuration to each job. It is therefore important that the information in the batch configuration is up to date. If, at any point, you edit this information in the external configuration, then you will be asked if you want to copy it to the batch configuration.\n\nPrevious: Normal mode configuration..\nNext: Creating Batch Jobs.",
    "crumbs": [
      "PAMGuard Website",
      "Batch Processing ",
      "Configure Offline Tasks"
    ]
  },
  {
    "objectID": "docs/batchjobs.html",
    "href": "docs/batchjobs.html",
    "title": "Creating Jobs",
    "section": "",
    "text": "Before you start processing, you need to set up one or more “jobs”. Each job requires the name of a folder containing raw sound input data, the name of an output folder for binary data and the name of a database.\nThe information about each job is stored in a database table called Batch_processing.\n\nSetting up single jobs\nTo set up a single batch job, click on “Create Job” and a dialog will appear where you can enter the folder for source sound files, the name of the output binary folder and the name of the output database. The dialog differs slightly depending on whether you are setting up normal mode jobs or offline tasks. When setting up normal jobs, you start with sound files and tell the batch processor where to create the output binary files and database, whereas when you set up offline tasks, you’re starting with an existing PAMGuard database which should already ‘know’ where the binary files are.\n\n\n\n\n\n\n\n\n\n\n\n\n\nDialog for creating jobs in normal mode\nDialog for creating jobs for offline tasks\n\n\n\n\n\nSetting up multiple jobs (normal mode)\nIf all of your raw data are in multiple folders on the same hard drive, then it’s easy to set up multiple jobs at once. Click the “Create Set” button and select the folder that contains sub folders for each set of data. The files within the sub folders will be searched for sound files to see how many jobs to create. Then select a root folder for databases and a root folder for binary file output. The jobs will then be automatically created with output binary folder names and database names based on the names of the sub folders containing the raw data. For example, if you had data from six deployments named “Deploy1” … “Deploy6” all in a folder D:/BatchDataSample/raw as shown in the figure below, then simply set the source folder to D:/BatchDataSample/raw and the program will find the six sub folders.\n \nThen select output folders for the binary data and for the databases, which need not be in the same root, but could be anywhere else on your system (e.g. the raw data may be on a server or external hard drive but you write the outputs to your local C drive)\nOnce you close the dialog, all six jobs will be created and will appear in the jobs table.\n \nNote that nothing will appear yet in the selected output folder. Binary output folders and databases will be created when each job runs. After all six jobs were complete the output folder looked like this, containing six folders of binary data and six databases:\n\n\nCalibration Data\nEven if you’ve deployed near identical instruments, you may have slightly different calibration data for each one, or perhaps hydrophone spacing changed slightly in towed arrays used in different years. To make changes to the hydrophone configuration for each job, right click on the row in the jobs table and select “Add job specific calibration / array data” from the menu. This will open the hydrophone array dialog, where you can update values for hydrophone calibrations and for their exact positions. This will be used to update the configuration for each job just before it runs.\n\n\n\nSetting up jobs for offline tasks\nThis is very similar to setting up jobs for normal operation, but instead of selecting a folder containing folders of sound files, you’ll select a folder containing multiple PAMGuard databases.\n\nThe selected folder will be searched for databases (ignoring the one used for the batch processor configuration if it happens to be in the same folder). Details of binary file locations and sound file locations will be automatically extracted from the databases. Note though that these may not be correct if date have moved (e.g. on external hard drives), so you may need to edit the individual jobs once created.\nMost offline tasks don’t require raw audio data and will be working only on the existing detections, so it’s often not a problem if the raw audio is not available.\n\n\nEditing jobs\nIndividual jobs can be edited by right clicking on a line in the main jobs table.\n\n\nDeleting Jobs\nCreated jobs will all appear in the main table in the lower half of the display. You can delete a job by right clicking on it and selecting “Delete Job” from the dropdown menu.\nIf you want to delete multiple jobs, it’s sometimes easier to close PAMGuard and delete jobs from the BatchJobs table.\n\n\nCheating\nSometimes, the job creation functions aren’t quite what you need, or only partially does the job. For example, what if you’re setting up jobs for processing offline tasks, and the binary data locations extracted from your set of databases are no no longer valid due to an external hard drive change ? You can edit each job individually by right clicking on each job on the display, which is OK if there are only a few of them, but if there are many dozens, for instance from a large deployment of autonomous recorders, you might want to change the file locations directly in the batch processor database.\nPAMGuard will have locked access to the database, so close PAMGuard, then alter the table “Batch_Processing”. You can do this manually, but you might also write a script in R or Matlab to alter the data for you. If adding new records, rather than just changing existing ones, make sure that their Id and UID are unique, and as a minimum, fill out the columns Id, UID, UTC (it doesn’t really matter what you put, so long as it’s a valid date time), Source (not strictly necessary for offline tasks), Binary, and Database.\nOne thing you can’t change in this way is the Array Data for each job. That’s because this bit of data is a stored (serialized) Java object which can only be read from Java when the correct PAMGuard array class definitions are available. It’s not impossible to automate changing these, but is more difficult. In short, you’ll need to write your own PAMGuard plugin module which has access to the PAMGuard classes, and therefore ‘knows’ what data it wants to enter for the hydrophone data, and can write those objects directly the to the database. If you think you need to do this please contact PAMGuard support.\nPrevious: Configuring the batch processor.\nNext: Running batch jobs.",
    "crumbs": [
      "PAMGuard Website",
      "Batch Processing ",
      "Creating Jobs"
    ]
  },
  {
    "objectID": "docs/batchrun.html",
    "href": "docs/batchrun.html",
    "title": "Running",
    "section": "",
    "text": "Modern computers have multiple processor cores, allowing them to perform several tasks simultaneously. For example, my desktop has 12 and my laptop 10. PAMGuard is designed so that each module will run semi-independently on a different core, but it’s really only the detectors and some of the sound processing modules that use much power. So depending on the complexity of your PAMGuard configuration, it’s unlikely that it will be using all of the power of all of the cores. Therefore you can usually run several instances of PAMGuard simultaneously, without any of them slowing down. However, if you add too many, then things will slow down overall, and you’re system may run out of memory.\nHow many PAMGuard’s can run concurrently depends on the complexity of your configuration and the power of your machine. Generally though, I find that I can run three or four PAMGuards at once before the system starts to become slow, or even unstable.\nThe default number of concurrent jobs in the batch processor module is 3. You can change this at any time by right clicking on the single line in the processor table.\n\nYou can increase or decrease the number of jobs at any time. If you increase it while the processes are running, then another process will launch after a few seconds. If you decrease it, not jobs will stop, but when the next one finished, another will not start until the total number running drops below the new selected maximum.\n\nStarting\nOnce all your jobs are ready, press the PAMGuard start button. The set number of jobs will launch after a few seconds and start to run. When each job finishes, that instance of PAMGuard will close and the next job will launch until all jobs are complete.\nJob progress is shown in the Jobs table on the display and is regularly written to the database.\n\n\n\nStopping\nTo stop batch processing, press the PAMGuard ‘stop’ button on the Batch Processor PAMGuard. You will then probably have to also stop any other instances of PAMGuard that are still running.\nIf you start one of the running instances, then it’s likely that the Batch control system will immediately start the next job in the list.\n\n\nRerunning and data overwriting (normal mode jobs)\nYou may want to reprocess your data, for instance if you’ve made a change to the configuration, or you may have to restart, for example if there was an error or even a Windows restart over the weekend. There are several options as to how PAMGuard should behave when restarting, which can be selected from the “Incomplete Sets …” menu in the Job Control panel.\n\n\nStart normally. Note risk of overwriting!\nThis is not recommended since the database may end up with two copies of output data. Furthermore binary files, which are generally started on the hour sometimes get slightly different file names so some files (that had an identical name) will be overwritten, and others which got a slightly different name won’t be.\n\n\nContinue from start of last input file processed\nThis is a sensible option to select if processing stopped for some reason half way through a bit dataset. PAMGuard will go to the start of the input file and attempt to delete any existing data from the existing binary files and database which come after that time before starting from where it left off.\n\n\nContinue from start of next input file to process\nThis is similar to the previous options, but might leave a gap in your data. It can be useful if there is one “problem file” that you’re prepared to give up on.\n\n\nDon’t start processing\nDon’t start if there are any existing data.\n\n\nOverwrite all existing output data\nAs it says, all existing data will be deleted for each job before processing starts. This is the most sensible option to select if you’ve changed your configuration and want to reprocess from scratch.\n\n\n\nOffline tasks\nIf running offline tasks, the selected jobs will run on each entire dataset.\nPrevious: Creating Batch Jobs.",
    "crumbs": [
      "PAMGuard Website",
      "Batch Processing ",
      "Running"
    ]
  }
]